<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Opencv JS</title>
    <!-- Load OpenCV -->
    <script async src="js/opencv.js" onload="openCvReady();"></script>
    <script src="js/utils.js"></script>
    <style>
        #cam_input {
            display: none;
        }

        #canvas_output {
            position: absolute;
            top: 0;
            left: 0;
            width: 100vw;
            height: 100vh;
            object-fit: cover;
        }

        /* Style for the container holding images */
        #image_container {
            position: absolute;
            top: 10px; /* Adjust positioning as needed */
            left: 10px;
            z-index: 10; /* Make sure images are on top of the video */
            display: flex;
            flex-wrap: wrap;
            gap: 10px;
        }

        .scraped-image {
            max-width: 150px; /* Adjust size as needed */
            max-height: 150px;
            border: 2px solid white;
        }

        body, html {
            margin: 0;
            padding: 0;
            overflow: hidden;
            background: black;
        }
    </style>
</head>
<body>
    <video id="cam_input" height="480" width="640"></video>
    <canvas id="canvas_output"></canvas>
    <!-- Image container to display scraped images -->
    <div id="image_container"></div>

    <!-- Regular script tag to ensure openCvReady is available globally -->
    <script>
    function openCvReady() {
        cv['onRuntimeInitialized'] = () => {
            let video = document.getElementById("cam_input");
            navigator.mediaDevices.getUserMedia({ video: true, audio: false })
            .then(function(stream) {
                video.srcObject = stream;
                video.play();
            })
            .catch(function(err) {
                console.log("An error occurred! " + err);
            });

            const canvas = document.getElementById('canvas_output');
            let src = new cv.Mat(video.height, video.width, cv.CV_8UC4);
            let dst = new cv.Mat(video.height, video.width, cv.CV_8UC1);
            let gray = new cv.Mat();
            let cap = new cv.VideoCapture(video);
            let faces = new cv.RectVector();
            let classifier = new cv.CascadeClassifier();
            let utils = new Utils('errorMessage');
            let faceCascadeFile = 'haarcascade_frontalface_default.xml'; 
            utils.createFileFromUrl(faceCascadeFile, faceCascadeFile, () => {
                classifier.load(faceCascadeFile);
            });

            const FPS = 24;
            let faceTracked = false;
            let trackingStartTime = null;
            const trackingThreshold = 3000;
            let faceLocked = false; // Indicates whether the face has been locked

            // Event listener to reset face-locking process when Enter key is pressed
            document.addEventListener('keydown', function(event) {
                if (event.keyCode === 13) {  // Enter key pressed
                    resetFaceLocking();
                }
            });

            // Function to reset all face-locking variables
            function resetFaceLocking() {
                faceLocked = false;
                faceTracked = false;
                trackingStartTime = null;
                
                // Clear the image container
                const imageContainer = document.getElementById('image_container');
                imageContainer.innerHTML = ''; // Clear any images

                console.log("Face locking has been reset, and images have been cleared.");

            }

            function processVideo() {
                let begin = Date.now();
                
                cap.read(src);
                src.copyTo(dst);
                cv.cvtColor(dst, gray, cv.COLOR_RGBA2GRAY, 0);

                const minFaceSize = 50;
                const maxFaceSize = 300;
                let largestFace = null;
                let largestArea = 0;

                // Continue detecting faces even if faceLocked is true
                try {
                    classifier.detectMultiScale(gray, faces, 1.1, 3, 0);
                    
                    for (let i = 0; i < faces.size(); ++i) {
                        let face = faces.get(i);
                        let faceArea = face.width * face.height;
                        if (face.width > minFaceSize && face.height > minFaceSize &&
                            face.width < maxFaceSize && face.height < maxFaceSize) {
                            if (faceArea > largestArea) {
                                largestArea = faceArea;
                                largestFace = face;
                            }
                        }
                    }
                } catch (err) {
                    console.error("Error during face detection:", err);
                }

                // If a largest face is found, draw the rectangle
                if (largestFace) {
                    let point1 = new cv.Point(largestFace.x, largestFace.y);
                    let point2 = new cv.Point(largestFace.x + largestFace.width, largestFace.y + largestFace.height);
                    
                    // Change the rectangle color to red if the face is locked, otherwise green
                    let color = faceLocked ? [255, 0, 0, 255] : [0, 255, 0, 255];
                    cv.rectangle(dst, point1, point2, color, 2);

                    // Start tracking time if not already started
                    if (!trackingStartTime) {
                        trackingStartTime = Date.now();
                    } else if (Date.now() - trackingStartTime > trackingThreshold && !faceTracked) {
                        faceTracked = true;

                        // Once the face has been tracked for more than 3 seconds, lock the face
                        if (!faceLocked) {
                            console.log("Face has been tracked for more than 3 seconds!");
                            captureFaceScreenshot(largestFace); // Capture screenshot once
                            faceLocked = true;  // Lock the face

                            // Scrape images test
                            displayScrapedImages();
                        }
                    }
                } else {
                    trackingStartTime = null;
                    faceTracked = false;
                }

                try {
                    cv.imshow("canvas_output", dst);
                } catch (err) {
                    console.error("Error displaying output on canvas:", err);
                }

                let delay = 1000 / FPS - (Date.now() - begin);
                setTimeout(processVideo, Math.max(0, delay));
            }

            function captureFaceScreenshot(face) {
                let canvas = document.createElement('canvas');
                let context = canvas.getContext('2d');
                canvas.width = face.width;
                canvas.height = face.height;
                let canvasOutput = document.getElementById('canvas_output');
                context.drawImage(
                    canvasOutput,
                    face.x, face.y, face.width, face.height,
                    0, 0, face.width, face.height
                );
                let faceImage = canvas.toDataURL('image/png');
                downloadImage(faceImage, 'face_screenshot.png');
            }

            function downloadImage(dataUrl, filename) {
                let link = document.createElement('a');
                link.href = dataUrl;
                link.download = filename;
                document.body.appendChild(link);
                link.click();
                document.body.removeChild(link);
            }

            // Function to display the scraped images over the video
            async function displayScrapedImages() {
                try {
                    const response = await fetch('http://localhost:3000/scrape-images'); // Backend URL
                    const data = await response.json();

                    if (data.success) {
                        const imageContainer = document.getElementById('image_container');
                        imageContainer.innerHTML = ''; // Clear any existing images

                        console.log(data)
                        data.images.forEach((src) => {
                            const img = document.createElement('img');
                            img.src = src;
                            img.className = 'scraped-image';
                            imageContainer.appendChild(img);
                        });
                    } else {
                        console.error('Error scraping images:', data.message);
                    }
                } catch (error) {
                    console.error('Error occurred during image scraping:', error);
                }
            }

            setTimeout(processVideo, 0);
        };
    }
    </script>
</body>
</html>
